# Session Summary: October 23, 2025 - Transition to ChromaDB

## Overview
This document summarizes the challenges encountered during the attempt to set up Milvus Lite, the subsequent decision to switch to ChromaDB, and the detailed next steps for continuing development on a fresh Runpod instance.

## Issues with Milvus Lite (Claude's Session & Initial Gemini Attempts)

**Problem:** The original plan called for Milvus, initially intended to be deployed via Docker Compose. Due to Runpod's GPU Pod limitations (no Docker Compose, no custom Docker builds), this approach was abandoned. Claude then attempted to transition the project to Milvus Lite, a lightweight, embedded version of Milvus.

**Challenges Encountered:**
1.  **`default_server.start()` Timeout:** Repeated attempts to run `ingest.py` with Milvus Lite resulted in the `default_server.start()` call timing out. This indicated that the embedded Milvus Lite server was failing to initialize or start within the Runpod environment.
2.  **`llama-index-vector-stores-milvus` Version:** It was identified that the installed version of `llama-index-vector-stores-milvus` (0.1.5) was older and did not fully support simple file-based URIs for Milvus Lite, contributing to the server startup issues.
3.  **Token Exhaustion (Claude):** Claude's session eventually ran out of tokens while trying to debug and resolve these Milvus Lite server startup issues.

## Decision to Switch to ChromaDB

Given the persistent problems with Milvus Lite's server startup and the strict Runpod Docker limitations, the decision was made to switch to **ChromaDB** in client-only (file-based) mode.

**Reasons for the switch:**
*   **Bypasses Server Issues:** ChromaDB in client-only mode does not require a separate server process, eliminating the `default_server.start()` timeout problem.
*   **Free and Open-Source:** Aligns with the project's cost-effectiveness goals.
*   **Future Scalability:** While client-only, it allows for future migration to more robust solutions (like Zilliz Cloud or a distributed Milvus cluster) when needed.
*   **Ease of Integration:** LlamaIndex provides good integration with ChromaDB.

## Code Changes Implemented for ChromaDB

The following changes were made to transition from Milvus Lite to ChromaDB:

1.  **`chromadb` Installation:** `chromadb` was installed via `pip` and added to `requirements.txt`. `pymilvus` and `milvus` were uninstalled to resolve dependency conflicts.
2.  **`backend/app/core/config.py`:**
    *   Removed `milvus_uri` and `milvus_collection_name`.
    *   Added `chroma_db_path` (set to `/root/AIMentorProject-1/backend/chroma_db`) and `chroma_collection_name` (set to `course_materials`).
3.  **`backend/ingest.py`:**
    *   Removed Milvus-specific imports (`MilvusVectorStore`, `default_server`, `pymilvus.utility`, `pymilvus.connections`).
    *   Added ChromaDB-specific imports (`ChromaVectorStore`, `chromadb`).
    *   Modified `connect_to_milvus()` (renamed to `prepare_chromadb()`) to initialize `chromadb.PersistentClient`.
    *   Modified `create_vector_store()` to use `ChromaVectorStore` and handle ChromaDB collection creation/deletion.
    *   Updated logging messages to reflect ChromaDB usage.
    *   Modified `main()` to call `prepare_chromadb()`.
4.  **`backend/app/services/rag_service.py`:**
    *   Removed Milvus-specific imports (`MilvusVectorStore`).
    *   Added ChromaDB-specific imports (`ChromaVectorStore`, `chromadb`).
    *   Modified `initialize()` to initialize `chromadb.PersistentClient` and `ChromaVectorStore`.
    *   Modified `get_stats()` to report `settings.chroma_collection_name`.

## Current Status & Next Steps (for Fresh Runpod Instance)

The code has been updated for ChromaDB, but the final ingestion test failed due to a "No space left on device" error on the current Runpod instance.

**For a brand new Runpod instance (with increased disk space), follow these detailed steps:**

1.  **Start New Runpod Instance:**
    *   Provision a new Runpod instance with **at least three times the disk space** of the previous one.
    *   Recommended GPU: RTX A5000 (24GB VRAM) or similar.
    *   Base image: `runpod/pytorch:1.0.2-cu1281-torch280-ubuntu2404` (or latest stable).
    *   Connect via VS Code Remote-SSH.

2.  **Initial System Setup & Dependencies:**
    ```bash
    sudo apt-get update && sudo apt-get install -y \
      python3-venv python3-pip python3-dev \
      nodejs npm git \
      build-essential cmake \
      wget curl htop tmux
    ```

3.  **Clone Project Repository:**
    ```bash
    cd /workspace
    git clone https://github.com/YOUR_USERNAME/AIMentorProject.git # Replace YOUR_USERNAME
    cd AIMentorProject
    chmod +x start_llm_server.sh # Ensure script is executable
    ```

4.  **Upload LLM Model from USB Drive:**
    *   **Create model directory:** `mkdir -p /workspace/models`
    *   **Upload `Mistral-7B-Instruct-v0.2.Q5_K_M.gguf`** (approx. 5.13 GB) from your local USB drive to `/workspace/models/` on the Runpod instance using VS Code Remote-SSH upload or SCP.
    *   **Verify:** `ls -lh /workspace/models/Mistral-7B-Instruct-v0.2.Q5_K_M.gguf`

5.  **Create Python Virtual Environment & Install Dependencies:**
    ```bash
    cd /workspace/AIMentorProject/backend
    python3 -m venv venv
    source venv/bin/activate
    pip install --upgrade pip
    pip install -r requirements.txt
    ```
    *Note: The `requirements.txt` file will now contain `chromadb` and exclude `pymilvus`.*

6.  **Start LLM Server:**
    *   This should be run in a detached `tmux` session to keep it running.
    ```bash
    cd /workspace/AIMentorProject
    tmux new-session -d -s llm './start_llm_server.sh'
    ```
    *   **Verify (after ~2 minutes):**
        ```bash
        curl http://localhost:8080/v1/models | jq
        ```

7.  **Create ChromaDB Data Directory:**
    ```bash
    mkdir -p /workspace/AIMentorProject/backend/chroma_db
    ```

8.  **Run Ingestion Script (with ChromaDB):**
    *   This will ingest your PDFs into the ChromaDB instance.
    ```bash
    cd /workspace/AIMentorProject/backend
    source venv/bin/activate
    HF_HUB_ENABLE_HF_TRANSFER=0 python ingest.py --directory ../course_materials/ --overwrite
    ```
    *   *Note: The `--overwrite` flag will ensure a clean start for the ChromaDB collection.*
    *   *The `HF_HUB_ENABLE_HF_TRANSFER=0` is crucial for the embedding model download.*

9.  **Start Backend FastAPI Server:**
    *   This should also be run in a detached `tmux` session.
    ```bash
    cd /workspace/AIMentorProject/backend
    tmux new-session -d -s api 'source venv/bin/activate && uvicorn main:app --host 0.0.0.0 --port 8000 --reload'
    ```
    *   **Verify (after a few seconds):**
        ```bash
        curl http://localhost:8000/ | jq
        curl http://localhost:8000/api/health | jq
        ```

10. **(Optional) Frontend Setup (on your local machine):**
    *   Follow the steps in `gemini_runpod_setup_guide.md` or `SIX_WEEK_EXECUTION_PLAN.md` for setting up the Svelte frontend locally, ensuring `VITE_API_BASE_URL` points to your Runpod instance's public IP.
